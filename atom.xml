<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hunterhawk&#39;s Blog</title>
  
  <subtitle>Beta Version</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://hunterhawk.github.io/"/>
  <updated>2019-08-30T08:22:35.902Z</updated>
  <id>http://hunterhawk.github.io/</id>
  
  <author>
    <name>Hunterhawk</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>泰坦尼克号数据科学解决方案</title>
    <link href="http://hunterhawk.github.io/2019/08/30/Titanic-data-science-solutions-translation/"/>
    <id>http://hunterhawk.github.io/2019/08/30/Titanic-data-science-solutions-translation/</id>
    <published>2019-08-30T08:20:48.000Z</published>
    <updated>2019-08-30T08:22:35.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="泰坦尼克号数据科学解决方案"><a href="#泰坦尼克号数据科学解决方案" class="headerlink" title="泰坦尼克号数据科学解决方案"></a>泰坦尼克号数据科学解决方案</h1><blockquote><p><a href="https://www.kaggle.com/startupsci/titanic-data-science-solutions" target="_blank" rel="noopener">原文链接</a><br>该笔记是<a href="https://www.amazon.com/Data-Science-Solutions-Startup-Workflow/dp/1520545312" target="_blank" rel="noopener">Data Science Solutions</a>一书的配套产品。<br>该笔记引导我们完成解决Kaggle等网站数据科学竞赛的典型工作流程。<br>已经存在几个优秀的笔记来研究数据科学竞赛的入门。然而，许多笔记会跳过关于如何开发解决方案的一些解释，这是因为这些笔记本是由专家开发，并为专家而作的。本笔记的目标是按照一步步进行的工作流程，解释我们在解决方案开发过程中做出的每个决定的每个步骤和基本原理。</p></blockquote><h2 id="工作流程阶段介绍"><a href="#工作流程阶段介绍" class="headerlink" title="工作流程阶段介绍"></a>工作流程阶段介绍</h2><p>以<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">Titanic: Machine Learning from Disaster</a>竞赛为例，<br>解决方案的工作流程经历了<a href="https://www.amazon.com/Data-Science-Solutions-Startup-Workflow/dp/1520545312" target="_blank" rel="noopener">Data Science Solutions</a>一书中描述的七个阶段。分别如下：</p><ol><li>问题或难点的定义</li><li>获取训练和测试数据</li><li>对数据进行讨论，预处理，清洗</li><li>分析，识别模型并探索数据</li><li>建模，预测并解决问题</li><li>可视化，形成报告，呈现问题的解决步骤和最终解决方案</li><li>提供或提交结果</li></ol><p>上述的工作流程指示每个阶段的一般顺序。但是也存在一些例外的情况，比如：</p><ul><li>我们可以结合多个工作流程阶段。我们可以通过可视化数据进行分析。</li><li>执行早于指示的阶段。我们可能会在讨论前后分析数据。</li><li>在我们的工作流程中多次执行一个步骤。例如可视化阶段可以多次使用。</li><li>完全丢弃一个步骤。我们可能不需要供应阶段来进行产品化或服务我们的数据集针对某一比赛。</li></ul><h2 id="工作流程目标"><a href="#工作流程目标" class="headerlink" title="工作流程目标"></a>工作流程目标</h2><p><strong>分类</strong>。我们可能希望对样本进行识别或分类。我们可能还想了解不同类的含义或不同类与我们的解决方案目标的相关性。</p><p><strong>相关</strong>。我们可以基于训练数据集内的可用特征来解决问题。数据集中的哪些特征对我们的解决方案目标有重大贡献？从统计学上讲，特征和解决方案目标之间是否存在相关性？随着特征值的变化，解决方案状态是否也会发生变化并且反之也成立？这可以针对给定数据集中的数值特征和类别特征进行测试。我们可能还希望确定除后续目标和工作流程阶段的生存之外的特征之间的相关性。关联某些功能可能有助于创建，完善或更正特征。</p><p><strong>转换</strong>。对于建模阶段，我们需要准备数据。根据模型算法的选择，我们可能需要将所有特征转换为数值等效值。例如，将文本分类值转换为数值。</p><p><strong>完整</strong>。数据准备可能还需要我们估计特征中的任何缺失值。当没有缺失值时，模型算法可能最有效。</p><p><strong>纠正</strong>。我们还可以分析给定的训练数据集中的错误或可能在特征内提取值，并尝试纠正这些值或排除包含错误的样本。一种方法是检测我们的样本或特征中的任何异常值。如果某项特征无益于分析，或者可能会严重影响结果的正确性，我们也可能完全丢弃该特征。</p><p><strong>创建</strong>。我们是否可以基于现有特征或一组特征创建新特征，以便新特征遵循关联，转换和完整性目标。</p><p><strong>图表化</strong>。如何根据数据的性质和解决方案目标，来选择正确的可视化图表。</p><h2 id="重构发布于2017年1月29日"><a href="#重构发布于2017年1月29日" class="headerlink" title="重构发布于2017年1月29日"></a>重构发布于2017年1月29日</h2><p>我们基于(a)读者收到的评论，(b)将笔记本从Jupyter内核(2.7)移植到Kaggle内核(3.5)以及(c)审查几个最佳实践内核的问题，对笔记进行了重大的重构。</p><h3 id="用户评论"><a href="#用户评论" class="headerlink" title="用户评论"></a>用户评论</h3><ul><li>为某些操作组合训练和测试数据，例如将数据集中的标称值转换为数值。 （感谢@Sharan Naribole）</li><li>正确观察 - 近30％的乘客有兄弟姐妹和/或配偶。 （感谢@Reinhard）</li><li>正确解释逻辑回归系数。 （感谢@Reinhard）</li></ul><h3 id="移植问题"><a href="#移植问题" class="headerlink" title="移植问题"></a>移植问题</h3><ul><li>指定绘图尺寸，将图例添加到绘图中。</li></ul><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><ul><li>在项目早期执行特征相关分析。</li><li>使用多个图而不是叠加图来提高可读性。</li></ul><h2 id="问题或难点的定义"><a href="#问题或难点的定义" class="headerlink" title="问题或难点的定义"></a>问题或难点的定义</h2><p>诸如Kaggle在内的竞赛网站定义要解决的问题，或提出需要解答的问题，同时提供用于训练数据科学模型的数据集，以及根据测试数据集测试模型结果。泰坦尼克号幸存竞赛的问题定义在Kaggle中描述如下：</p><blockquote><p>根据已知训练数据集列出的在泰坦尼克号灾难中幸存的乘客的一组样本进行学习，我们的模型是否能够基于给定的不包含幸存信息的测试数据集，决策这些位于测试集中的乘客幸存与否。</p></blockquote><p>我们可能还希望对我们问题领域有一些预先的了解，这在<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">比赛描述页面</a>上有所描述，以下是需要注意的要点：</p><blockquote><p>1912年4月15日，在其处女航中，泰坦尼克号与冰山相撞后沉没，造成了2224名乘客和机组人员中1502人死亡。幸存率为32％。<br>造成此次海难失事的原因之一是乘客和机组人员没有足够的救生艇。<br>尽管在巨轮沉没中幸存有一些幸运因素，但有些人比其他人更容易幸存，例如妇女，儿童和上流社会阶层。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 数据分析及讨论</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import random as rnd</span><br><span class="line"></span><br><span class="line"># 可视化</span><br><span class="line">import seaborn as sns</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"># 机器学习</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">from sklearn.svm import SVC, LinearSVC</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from sklearn.naive_bayes import GaussianNB</span><br><span class="line">from sklearn.linear_model import Perceptron</span><br><span class="line">from sklearn.linear_model import SGDClassifier</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h2><p>Python Pandas包帮助我们处理数据集。我们首先将训练和测试数据集收集到Pandas DataFrames中。我们还组合这些数据集以便在两个数据集上一起运行某些操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df = pd.read_csv(&apos;../input/train.csv&apos;)</span><br><span class="line">test_df = pd.read_csv(&apos;../input/test.csv&apos;)</span><br><span class="line">combine = [train_df, test_df]</span><br></pre></td></tr></table></figure></p><h2 id="通过描述数据进行分析"><a href="#通过描述数据进行分析" class="headerlink" title="通过描述数据进行分析"></a>通过描述数据进行分析</h2><p>Pandas还帮助描述数据集，在我们的项目早期回答以下问题：</p><p><strong>数据集中有哪些特征？</strong></p><p>注意这些特征名称以便直接操作或分析，这些特征名称在<a href="https://www.kaggle.com/c/titanic/data" target="_blank" rel="noopener">Kaggle数据页面</a>中描述。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(train_df.columns.values)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&apos;PassengerId&apos; &apos;Survived&apos; &apos;Pclass&apos; &apos;Name&apos; &apos;Sex&apos; &apos;Age&apos; &apos;SibSp&apos; &apos;Parch&apos;</span><br><span class="line"> &apos;Ticket&apos; &apos;Fare&apos; &apos;Cabin&apos; &apos;Embarked&apos;]</span><br></pre></td></tr></table></figure><p><strong>哪些特征是类别的？</strong></p><p>这些值将样本分类为类似样本的集合。在分类特征中，其数值是否基于名义，序数，比率或区间？除此之外，这有助于我们选择适当的可视化图。</p><ul><li>类别型：Survived, Sex, and Embarked. 序数型: Pclass.</li></ul><p><strong>哪些特征是数值的？</strong></p><p>哪些功能是数值的？这些值随样本而变化。在数值特征中，值是离散的，连续的还是基于时间序列的？除此之外，这有助于我们选择适当的可视化图。</p><ul><li>连续型: Age, Fare. 离散型: SibSp, Parch.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 数据预览</span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>0</td><td>3</td><td>Braund, Mr.Owen Harris</td><td>male</td><td>22.0</td><td>1</td><td>0</td><td>A/5 21171</td><td>7.2500</td><td>NaN</td><td>S</td></tr><tr><td>1</td><td>2</td><td>1</td><td>1</td><td>Cumings, Mrs.John Bradley(Florence Briggs Th…</td><td>female</td><td>38.0</td><td>1</td><td>0</td><td>PC 17599</td><td>71.2833</td><td>C85</td><td>C</td></tr><tr><td>2</td><td>3</td><td>1</td><td>3</td><td>Heikkinen, Miss. Laina</td><td>female</td><td>26.0</td><td>0</td><td>0</td><td>STON/O2. 3101282</td><td>7.9250</td><td>NaN</td><td>S</td></tr><tr><td>3</td><td>4</td><td>1</td><td>1</td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td><td>female</td><td>35.0</td><td>1</td><td>0</td><td>113803</td><td>5301000</td><td>C123</td><td>S</td></tr><tr><td>4</td><td>5</td><td>0</td><td>3</td><td>Allen, Mr. William Henry</td><td>male</td><td>35.0</td><td>0</td><td>0</td><td>373450</td><td>8.0500</td><td>NaN</td><td>S</td></tr></tbody></table><p><strong>哪些特征是混合数据类型？</strong></p><p>同一特征内的数字，字母数值数据。这些是修正目标的候选。</p><ul><li>Ticket是数字和字母数值数据类型的混合。Cabin是字母数值。</li></ul><p><strong>哪些特征可能包含错误或拼写错误？</strong></p><p>对于大型数据集来说，这很难检查，但是从较小的数据集中查看一些样本就可以告诉我们，哪些特征可能需要更正。</p><ul><li>Name特征可能包含错误或拼写错误，因为有多种方法可用于描述姓名，包括标题，圆括号和用于替代或短名称的引号。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df.tail()</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image2.png" alt="image2"></p><p><strong>哪些功能包含blank，null或empty values？</strong></p><p>这些都需要纠正。</p><ul><li>Cabin &gt; Age &gt; Embarked 训练数据集中这些特征包含多个空值。</li><li>Cabin &gt; Age 在测试数据集中不完整。</li></ul><p><strong>各种特征的数据类型是什么？</strong></p><p>在转换目标时帮助我们。</p><ul><li>七个特征是整数或浮点数。在测试数据集的情况下为六个。</li><li>五个特征为字符串（对象）。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df.info()</span><br><span class="line">print(&apos;_&apos;*40)</span><br><span class="line">test_df.info()</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</span><br><span class="line">RangeIndex: 891 entries, 0 to 890</span><br><span class="line">Data columns (total 12 columns):</span><br><span class="line">PassengerId    891 non-null int64</span><br><span class="line">Survived       891 non-null int64</span><br><span class="line">Pclass         891 non-null int64</span><br><span class="line">Name           891 non-null object</span><br><span class="line">Sex            891 non-null object</span><br><span class="line">Age            714 non-null float64</span><br><span class="line">SibSp          891 non-null int64</span><br><span class="line">Parch          891 non-null int64</span><br><span class="line">Ticket         891 non-null object</span><br><span class="line">Fare           891 non-null float64</span><br><span class="line">Cabin          204 non-null object</span><br><span class="line">Embarked       889 non-null object</span><br><span class="line">dtypes: float64(2), int64(5), object(5)</span><br><span class="line">memory usage: 83.6+ KB</span><br><span class="line">________________________________________</span><br><span class="line">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;</span><br><span class="line">RangeIndex: 418 entries, 0 to 417</span><br><span class="line">Data columns (total 11 columns):</span><br><span class="line">PassengerId    418 non-null int64</span><br><span class="line">Pclass         418 non-null int64</span><br><span class="line">Name           418 non-null object</span><br><span class="line">Sex            418 non-null object</span><br><span class="line">Age            332 non-null float64</span><br><span class="line">SibSp          418 non-null int64</span><br><span class="line">Parch          418 non-null int64</span><br><span class="line">Ticket         418 non-null object</span><br><span class="line">Fare           417 non-null float64</span><br><span class="line">Cabin          91 non-null object</span><br><span class="line">Embarked       418 non-null object</span><br><span class="line">dtypes: float64(2), int64(4), object(5)</span><br><span class="line">memory usage: 36.0+ KB</span><br></pre></td></tr></table></figure><p><strong>样本中数值特征值的分布是什么？</strong></p><p>这有助于我们在其他早期见解中确定实际问题域的训练数据集的代表性。</p><ul><li>总样本是泰坦尼克号上实际乘客人数(2224)的40％(891)。</li><li>Survived是一个具有0或1值的分类特征。</li><li>大约38％的样本存活，实际存活率为32％。</li><li>大多数乘客（&gt;75％）没有与父母或孩子一起旅行。</li><li>近30％的乘客有兄弟姐妹和/或配偶。</li><li>票价差异很大，很少有乘客（&lt;1％）支付高达512美元。</li><li>年龄在65-80岁之间的老年乘客（&lt;1％）很少。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_df.describe()</span><br><span class="line"># Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.</span><br><span class="line"># Review Parch distribution using `percentiles=[.75, .8]`</span><br><span class="line"># SibSp distribution `[.68, .69]`</span><br><span class="line"># Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image3.png" alt="image3"></p><p><strong>分类特征的分布是什么？</strong></p><ul><li>Name在整个数据集中是唯一的（count = unique = 891）</li><li>Sex变量为两个可能的值，男性为65％（top=男性，freq = 577 / count = 891）</li><li>Cabin值在样本中有几个副本。或者说，几个乘客共用一个客舱小屋。</li><li>Embarked有三个可能的值。大多数乘客使用的S港口（top = S）</li><li>Ticket特征有高比率（22%）的重复值（unique = 681）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_df.describe()</span><br><span class="line"># Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.</span><br><span class="line"># Review Parch distribution using `percentiles=[.75, .8]`</span><br><span class="line"># SibSp distribution `[.68, .69]`</span><br><span class="line"># Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image4.png" alt="image4"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df.describe(include=[&apos;O&apos;])</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image5.png" alt="image5"></p><h2 id="基于数据分析的假设"><a href="#基于数据分析的假设" class="headerlink" title="基于数据分析的假设"></a>基于数据分析的假设</h2><p>我们基于迄今为止所做的数据分析得出以下假设。我们可能会在采取适当行动之前进一步验证这些假设。</p><h3 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h3><p>我们想知道每个特征与生存的相关性。我们希望在项目的早期阶段完成这项工作，并将这些快速关联与项目后期的建模关联相匹配。</p><h3 id="补充完整"><a href="#补充完整" class="headerlink" title="补充完整"></a>补充完整</h3><ol><li>我们可能希望补充完整年龄特征，因为它与生存明确相关。</li><li>我们可能希望补充完整登船港口特征，因为它还可能与生存或其他重要特征相关联。<h3 id="修正"><a href="#修正" class="headerlink" title="修正"></a>修正</h3></li><li>船票编号特征可能会从我们的分析中删除，因为它包含高比例的重复项（22％），并且票价和生存之间可能没有相关性。</li><li>客舱特征可能会被删除，因为其极度不完整或者在训练和测试数据集中都包含许多空值。</li><li>PassengerId特征可能会从训练数据集中删除，因为它对生存没有贡献。</li><li>姓名特征相对不标准，可能无法直接影响生存，因此可能会被删除。<h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3></li><li>我们可能想要创建一个名为Family的基于Parch和SibSp的新特征，以获得船上家庭成员的总数。</li><li>我们可能希望设计姓名特征以将Title提取为新特征。</li><li>我们可能想为年龄范围创建新特征。这将连续的数字特征转换为序数分类特征（Ordinal categorical feature）。</li><li>如果其有助于我们的分析，我们可能还想创建一个票价范围特征。<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3>我们还可以根据前面提到的问题描述添加我们的假设。</li><li>女性（Sex = female）更有可能幸存下来。</li><li>儿童（Age &lt; ？）更有可能幸存下来。</li><li>上层乘客（Pclass = 1）更有可能幸存下来。（注：pclass：社会经济地位（SES）的代表）<h2 id="通过旋转特征进行分析"><a href="#通过旋转特征进行分析" class="headerlink" title="通过旋转特征进行分析"></a>通过旋转特征进行分析</h2>为了确认我们的一些观察和假设，我们可以通过相互转动特征来快速分析我们的特征相关性。在此阶段我们只能为没有任何空值的特征执行此操作。对于分类（Sex），序数（Pclass）或离散（SibSp，Parch）类型的特征，这样做也是有意义的。</li></ol><ul><li><strong>Pclass</strong> 我们观察到Pclass = 1和Survived之间的显著相关性（&gt; 0.5）<strong>（分类#3）</strong>。我们决定在我们的模型中包含此特征。</li><li><strong>Sex</strong> 我们在问题定义中确认Sex=female的生存率非常高，为74％<strong>（分类#1）</strong>。</li><li><strong>SibSp和Parch</strong> 这些特征对于某些值具有零相关性。最好从这些单独的特征中导出一个特征或一组特征<strong>（创建#1）</strong>。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[&apos;Pclass&apos;, &apos;Survived&apos;]].groupby([&apos;Pclass&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image6.png" alt="image6"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[&quot;Sex&quot;, &quot;Survived&quot;]].groupby([&apos;Sex&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image7.png" alt="image7"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[&quot;SibSp&quot;, &quot;Survived&quot;]].groupby([&apos;SibSp&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image8.png" alt="image8"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_df[[&quot;Parch&quot;, &quot;Survived&quot;]].groupby([&apos;Parch&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image9.png" alt="image9"></p><h2 id="通过可视化数据进行分析"><a href="#通过可视化数据进行分析" class="headerlink" title="通过可视化数据进行分析"></a>通过可视化数据进行分析</h2><p>现在我们可以继续使用可视化分析数据来确认我们的一些假设。</p><h3 id="关联数值特征"><a href="#关联数值特征" class="headerlink" title="关联数值特征"></a>关联数值特征</h3><p>让我们首先了解数值特征与我们的解决方案目标（存活）之间的相关性。</p><p>直方图可用于分析像Age这样的连续数值变量，其中条带或范围将有助于识别有用的模式。直方图可以使用自动定义的区间或等距离范围来指示样本的分布。这有助于我们回答与特定范围相关的问题（例如：婴儿的生存率是否更高？）</p><p>请注意，直方图可视化中的x轴表示样本或乘客的数量。</p><p><strong>观察</strong></p><ul><li>婴儿（Age &lt;= 4）的存活率很高。</li><li>最年长的乘客们（Age = 80岁）幸免于难。</li><li>大量15-25岁的人没有活下来。</li><li>大多数乘客年龄在15-35岁之间。</li></ul><p><strong>决策</strong></p><p>这个简单的分析证实了我们作为后续工作流程阶段决策的假设。</p><ul><li>我们应该在模型训练中考虑年龄特征。<strong>（我们的假设分类#2）</strong></li><li>补充完整年龄特征的那些空值。<strong>（补充完整#1）</strong></li><li>我们应该将年龄特征进行范围分组。<strong>（创建#3）</strong><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">g = sns.FacetGrid(train_df, col=&apos;Survived&apos;)</span><br><span class="line">g.map(plt.hist, &apos;Age&apos;, bins=20)</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image10.png" alt="image10"></p><h3 id="关联数值和有序特征"><a href="#关联数值和有序特征" class="headerlink" title="关联数值和有序特征"></a>关联数值和有序特征</h3><p>我们可以使用单个图组合多个特征来识别相关性。这可以通过具有数值的数值特征和分类特征来完成。</p><p><strong>观察</strong></p><ul><li>Pclass = 3 有大多数乘客，但大多数人没有幸存。确认了我们的<strong>分类假设#2</strong>。</li><li>Pclass = 2和Pclass = 3的婴儿乘客大部分幸存下来。进一步限定了我们的<strong>分类假设#2</strong>。</li><li>Pclass = 1的大多数乘客幸免于难。确认了我们的<strong>分类假设#3</strong>。</li><li>Pclass在乘客年龄分布方面有所不同。</li></ul><p><strong>决策</strong></p><ul><li>考虑使用Pclass进行模型训练。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># grid = sns.FacetGrid(train_df, col=&apos;Pclass&apos;, hue=&apos;Survived&apos;)</span><br><span class="line">grid = sns.FacetGrid(train_df, col=&apos;Survived&apos;, row=&apos;Pclass&apos;, size=2.2, aspect=1.6)</span><br><span class="line">grid.map(plt.hist, &apos;Age&apos;, alpha=.5, bins=20)</span><br><span class="line">grid.add_legend();</span><br></pre></td></tr></table></figure></li></ul><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image11.png" alt="image11"></p><h3 id="关联类别特征"><a href="#关联类别特征" class="headerlink" title="关联类别特征"></a>关联类别特征</h3><p>现在我们可以将分类特征与我们的解决方案目标相关联。</p><p><strong>观察</strong></p><ul><li>女性乘客的生存率远高于男性。<strong>(分类假设#1)</strong></li><li>在Embarked = C中的例外情况，其中雄性具有更高的存活率。这可能是Pclass和Embarked之间的相关性，反过来是Pclass和Survived，不一定是Embarked和Survived之间的直接相关。</li><li>与C、Q港口的Pclass = 2相比，男性在Pclass = 3时的存活率更高。<strong>(补充完整假设#2)</strong></li><li>登船口岸的Pclass = 3和男性乘客的生存率各不相同。<strong>(相关假设#1)</strong></li></ul><p><strong>决策</strong></p><ul><li>将性别特征添加到模型训练中。</li><li>补充完整并添加登船口岸特征以进行模型训练。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># grid = sns.FacetGrid(train_df, col=&apos;Embarked&apos;)</span><br><span class="line">grid = sns.FacetGrid(train_df, row=&apos;Embarked&apos;, size=2.2, aspect=1.6)</span><br><span class="line">grid.map(sns.pointplot, &apos;Pclass&apos;, &apos;Survived&apos;, &apos;Sex&apos;, palette=&apos;deep&apos;)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image12.png" alt="image12"></p><h3 id="关联类别和数值特征"><a href="#关联类别和数值特征" class="headerlink" title="关联类别和数值特征"></a>关联类别和数值特征</h3><p>我们还可以将分类特征（使用非数值的值）和数值特征相关联。 我们可以考虑将登船口岸（分类非数值特征），性别（分类非数值特征），票价（数值连续特征）与幸存（分类数值特征）相关联。</p><p><strong>观察</strong></p><ul><li>船票付费较高的乘客有更好的幸存率。这确认我们 <strong>创建假设(#4)</strong> 关于票价范围的假设。</li><li>登船口岸与幸存率相关。<strong>相关假设(#1)和补充完整假设(#2)</strong></li></ul><p><strong>决策</strong></p><ul><li>考虑票价范围特征。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># grid = sns.FacetGrid(train_df, col=&apos;Embarked&apos;, hue=&apos;Survived&apos;, palette=&#123;0: &apos;k&apos;, 1: &apos;w&apos;&#125;)</span><br><span class="line">grid = sns.FacetGrid(train_df, row=&apos;Embarked&apos;, col=&apos;Survived&apos;, size=2.2, aspect=1.6)</span><br><span class="line">grid.map(sns.barplot, &apos;Sex&apos;, &apos;Fare&apos;, alpha=.5, ci=None)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image13.png" alt="image13"></p><h2 id="讨论数据"><a href="#讨论数据" class="headerlink" title="讨论数据"></a>讨论数据</h2><p>我们收集了有关数据集和解决方案要求的若干假设和决策。 到目前为止，我们没有必要更改单个功能或值来实现这些功能。 现在让我们执行我们的决策和假设，以纠正，创建和完成目标。</p><h3 id="通过丢弃特征进行修正"><a href="#通过丢弃特征进行修正" class="headerlink" title="通过丢弃特征进行修正"></a>通过丢弃特征进行修正</h3><p>这是一个很好的起始目标。通过删除特征，我们处理的数据点更少。加速我们的笔记本电脑并简化分析。</p><p>根据我们的假设和决策，我们希望丢弃Cabin <strong>(修正#2)</strong> 和Ticket <strong>(修正#1)</strong> 特征。</p><p>请注意，在适用的情况下，我们同时对训练数据集和测试数据集执行操作以保持一致。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;Before&quot;, train_df.shape, test_df.shape, combine[0].shape, combine[1].shape)</span><br><span class="line"></span><br><span class="line">train_df = train_df.drop([&apos;Ticket&apos;, &apos;Cabin&apos;], axis=1)</span><br><span class="line">test_df = test_df.drop([&apos;Ticket&apos;, &apos;Cabin&apos;], axis=1)</span><br><span class="line">combine = [train_df, test_df]</span><br><span class="line"></span><br><span class="line">&quot;After&quot;, train_df.shape, test_df.shape, combine[0].shape, combine[1].shape</span><br></pre></td></tr></table></figure></p><blockquote><p>Before (891, 12) (418, 11) (891, 12) (418, 11)<br>(‘After’, (891, 10), (418, 9), (891, 10), (418, 9))</p></blockquote><h3 id="从现有特征提取创建新特征"><a href="#从现有特征提取创建新特征" class="headerlink" title="从现有特征提取创建新特征"></a>从现有特征提取创建新特征</h3><p>我们想要分析是否可以设计Name特征来提取Title(头衔)并测试Title(头衔)和生存之间的相关性，然后再删除Name和PassengerId功能。</p><p>在下面的代码中，我们使用正则表达式提取标题功能。 RegEx模式 <strong>(\w+.)</strong> 匹配Name特征中以.字符结尾的第一个单词。expand = False标志返回一个DataFrame。</p><p><strong>观察</strong></p><p>当我们绘制Title，Age和Survived时，我们注意到以下观察结果。</p><ul><li>大多数头衔准确地将年龄组带入例如：主标题的年龄均值为5年。</li><li>Title年龄段的生存率略有不同。</li><li>某些头衔大多存活下来(Mme，Lady，Sir)，而某些大多没有存活下来(Don，Rev，Jonkheer)。</li></ul><p><strong>决策</strong></p><ul><li>我们决定保留新的Title(头衔)特征以进行模型训练。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset.Name.str.extract(&apos; ([A-Za-z]+)\.&apos;, expand=False)</span><br><span class="line"></span><br><span class="line">pd.crosstab(train_df[&apos;Title&apos;], train_df[&apos;Sex&apos;])</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image14.png" alt="image14"><br>我们可以用更常见的Name替换许多Title(头衔)或将它们归类为Rare(稀少)。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].replace([&apos;Lady&apos;, &apos;Countess&apos;,&apos;Capt&apos;, &apos;Col&apos;,\</span><br><span class="line"> &apos;Don&apos;, &apos;Dr&apos;, &apos;Major&apos;, &apos;Rev&apos;, &apos;Sir&apos;, &apos;Jonkheer&apos;, &apos;Dona&apos;], &apos;Rare&apos;)</span><br><span class="line"></span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].replace(&apos;Mlle&apos;, &apos;Miss&apos;)</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].replace(&apos;Ms&apos;, &apos;Miss&apos;)</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].replace(&apos;Mme&apos;, &apos;Mrs&apos;)</span><br><span class="line"></span><br><span class="line">train_df[[&apos;Title&apos;, &apos;Survived&apos;]].groupby([&apos;Title&apos;], as_index=False).mean()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image15.png" alt="image15"><br>我们可以将类别标题转换为序数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">title_mapping = &#123;&quot;Mr&quot;: 1, &quot;Miss&quot;: 2, &quot;Mrs&quot;: 3, &quot;Master&quot;: 4, &quot;Rare&quot;: 5&#125;</span><br><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].map(title_mapping)</span><br><span class="line">    dataset[&apos;Title&apos;] = dataset[&apos;Title&apos;].fillna(0)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image16.png" alt="image16"><br>现在我们可以安全地从训练数据集和测试数据集中删除Name特征。我们也不需要训练数据集中的PassengerId特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([&apos;Name&apos;, &apos;PassengerId&apos;], axis=1)</span><br><span class="line">test_df = test_df.drop([&apos;Name&apos;], axis=1)</span><br><span class="line">combine = [train_df, test_df]</span><br><span class="line">train_df.shape, test_df.shape</span><br></pre></td></tr></table></figure></p><blockquote><p>((891, 9), (418, 9))</p></blockquote><h3 id="转换类别特征"><a href="#转换类别特征" class="headerlink" title="转换类别特征"></a>转换类别特征</h3><p>现在我们可以将包含字符串的特征转换为数值。这是大多数模型算法所必需的。这样做也将有助于我们实现特征补充完整的目标。</p><p>让我们首先将性别特征转换为名为Gender的新特征，其中 female = 1，male = 0。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Sex&apos;] = dataset[&apos;Sex&apos;].map( &#123;&apos;female&apos;: 1, &apos;male&apos;: 0&#125; ).astype(int)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image17.png" alt="image17"></p><h3 id="补充完整数值连续特征"><a href="#补充完整数值连续特征" class="headerlink" title="补充完整数值连续特征"></a>补充完整数值连续特征</h3><p>现在我们应该开始估计和补充缺少值(missing)或空值(null)的特征。我们将首先为Age特征执行此操作。</p><p>我们可以考虑三种方法来补充数值连续特征。</p><ol><li>一种简单的方法是在均值和标准差之间生成随机数。</li><li>猜测缺失值的更准确方法是使用其他相关特征。 在我们的例子中，我们注意到Age，Gender和Pclass之间的相关性。使用Pclass和Gender特征组合的集合的中值来猜测Age年龄值。因此，统计(Pclass=1, Gender=0)，(Pclass=1, Gender=1)的Age年龄中值以及更多……</li><li>结合上述方法1和2。因此，不是基于中位数来猜测年龄值，而是根据Pclass和Gender组合的集合使用均值和标准差之间的随机数。</li></ol><p>方法1和3会将随机噪声引入我们的模型。多次执行的结果可能会有所不同。我们更喜欢方法2。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># grid = sns.FacetGrid(train_df, col=&apos;Pclass&apos;, hue=&apos;Gender&apos;)</span><br><span class="line">grid = sns.FacetGrid(train_df, row=&apos;Pclass&apos;, col=&apos;Sex&apos;, size=2.2, aspect=1.6)</span><br><span class="line">grid.map(plt.hist, &apos;Age&apos;, alpha=.5, bins=20)</span><br><span class="line">grid.add_legend()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image18.png" alt="image18"><br>我们首先准备一个空数组，以包含基于Pclass 与 Gender组合而得到的Age猜测值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">guess_ages = np.zeros((2,3))</span><br><span class="line">guess_ages</span><br></pre></td></tr></table></figure></p><blockquote><p>array([[0., 0., 0.],<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[0., 0., 0.]])</p></blockquote><p>现在我们迭代Sex(0或1)和Pclass(1,2,3)来计算六种组合的Age的猜测值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    for i in range(0, 2):</span><br><span class="line">        for j in range(0, 3):</span><br><span class="line">            guess_df = dataset[(dataset[&apos;Sex&apos;] == i) &amp; \</span><br><span class="line">                                  (dataset[&apos;Pclass&apos;] == j+1)][&apos;Age&apos;].dropna()</span><br><span class="line"></span><br><span class="line">            # age_mean = guess_df.mean()</span><br><span class="line">            # age_std = guess_df.std()</span><br><span class="line">            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)</span><br><span class="line"></span><br><span class="line">            age_guess = guess_df.median()</span><br><span class="line"></span><br><span class="line">            # Convert random age float to nearest .5 age</span><br><span class="line">            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5</span><br><span class="line"></span><br><span class="line">    for i in range(0, 2):</span><br><span class="line">        for j in range(0, 3):</span><br><span class="line">            dataset.loc[ (dataset.Age.isnull()) &amp; (dataset.Sex == i) &amp; (dataset.Pclass == j+1),\</span><br><span class="line">                    &apos;Age&apos;] = guess_ages[i,j]</span><br><span class="line"></span><br><span class="line">    dataset[&apos;Age&apos;] = dataset[&apos;Age&apos;].astype(int)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image19.png" alt="image19"></p><p>创建年龄段并确定与幸存的相关性。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_df[&apos;AgeBand&apos;] = pd.cut(train_df[&apos;Age&apos;], 5)</span><br><span class="line">train_df[[&apos;AgeBand&apos;, &apos;Survived&apos;]].groupby([&apos;AgeBand&apos;], as_index=False).mean().sort_values(by=&apos;AgeBand&apos;, ascending=True)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image20.png" alt="image20"></p><p>根据这些范围将年龄值替换为序数。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset.loc[ dataset[&apos;Age&apos;] &lt;= 16, &apos;Age&apos;] = 0</span><br><span class="line">    dataset.loc[(dataset[&apos;Age&apos;] &gt; 16) &amp; (dataset[&apos;Age&apos;] &lt;= 32), &apos;Age&apos;] = 1</span><br><span class="line">    dataset.loc[(dataset[&apos;Age&apos;] &gt; 32) &amp; (dataset[&apos;Age&apos;] &lt;= 48), &apos;Age&apos;] = 2</span><br><span class="line">    dataset.loc[(dataset[&apos;Age&apos;] &gt; 48) &amp; (dataset[&apos;Age&apos;] &lt;= 64), &apos;Age&apos;] = 3</span><br><span class="line">    dataset.loc[ dataset[&apos;Age&apos;] &gt; 64, &apos;Age&apos;]</span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image21.png" alt="image21"></p><p>我们现在可以删除AgeBand特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([&apos;AgeBand&apos;], axis=1)</span><br><span class="line">combine = [train_df, test_df]</span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image22.png" alt="image22"></p><h3 id="组合现有特征，创建新特征"><a href="#组合现有特征，创建新特征" class="headerlink" title="组合现有特征，创建新特征"></a>组合现有特征，创建新特征</h3><p>我们可以为FamilySize创建一个新特征，它结合了Parch和SibSp。这将使我们能够从数据集中删除Parch和SibSp特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;FamilySize&apos;] = dataset[&apos;SibSp&apos;] + dataset[&apos;Parch&apos;] + 1</span><br><span class="line"></span><br><span class="line">train_df[[&apos;FamilySize&apos;, &apos;Survived&apos;]].groupby([&apos;FamilySize&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image23.png" alt="image23"></p><p>我们可以创建另一个名为IsAlone的特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;IsAlone&apos;] = 0</span><br><span class="line">    dataset.loc[dataset[&apos;FamilySize&apos;] == 1, &apos;IsAlone&apos;] = 1</span><br><span class="line"></span><br><span class="line">train_df[[&apos;IsAlone&apos;, &apos;Survived&apos;]].groupby([&apos;IsAlone&apos;], as_index=False).mean()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image24.png" alt="image24"></p><p>让我们删除Parch，SibSp和FamilySize特征，转而使用IsAlone特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_df = train_df.drop([&apos;Parch&apos;, &apos;SibSp&apos;, &apos;FamilySize&apos;], axis=1)</span><br><span class="line">test_df = test_df.drop([&apos;Parch&apos;, &apos;SibSp&apos;, &apos;FamilySize&apos;], axis=1)</span><br><span class="line">combine = [train_df, test_df]</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image25.png" alt="image25"></p><p>我们还可以创建一个结合Pclass和Age的人工特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Age*Class&apos;] = dataset.Age * dataset.Pclass</span><br><span class="line"></span><br><span class="line">train_df.loc[:, [&apos;Age*Class&apos;, &apos;Age&apos;, &apos;Pclass&apos;]].head(10)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image26.png" alt="image26"></p><h3 id="补充完整类别特征"><a href="#补充完整类别特征" class="headerlink" title="补充完整类别特征"></a>补充完整类别特征</h3><p>登船口岸特征根据登船港口获取S，Q，C值。我们的训练数据集有两个缺失值。我们简单地用最常见的值补充这两个值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">freq_port = train_df.Embarked.dropna().mode()[0]</span><br><span class="line">freq_port</span><br></pre></td></tr></table></figure></p><blockquote><p>‘S’</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Embarked&apos;] = dataset[&apos;Embarked&apos;].fillna(freq_port)</span><br><span class="line"></span><br><span class="line">train_df[[&apos;Embarked&apos;, &apos;Survived&apos;]].groupby([&apos;Embarked&apos;], as_index=False).mean().sort_values(by=&apos;Survived&apos;, ascending=False)</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image27.png" alt="image27"></p><h3 id="将类别特征转换为数值特征"><a href="#将类别特征转换为数值特征" class="headerlink" title="将类别特征转换为数值特征"></a>将类别特征转换为数值特征</h3><p>我们现在可以通过创建新的数值登船口岸特征来转换EmbarkedFill特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset[&apos;Embarked&apos;] = dataset[&apos;Embarked&apos;].map( &#123;&apos;S&apos;: 0, &apos;C&apos;: 1, &apos;Q&apos;: 2&#125; ).astype(int)</span><br><span class="line"></span><br><span class="line">train_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image28.png" alt="image28"></p><h3 id="快速补充并转换数值特征"><a href="#快速补充并转换数值特征" class="headerlink" title="快速补充并转换数值特征"></a>快速补充并转换数值特征</h3><p>现在，我们可以使用模型为测试数据集中的单个缺失值完成“票价”功能，以获取此特征最常出现的值。我们在一行代码中完成此操作。</p><p>请注意，由于我们只替换单个值，因此我们不会创建中间新特征或进行任何进一步的相关分析以猜测缺失特征。 该补充目标实现了模型算法对非空值进行操作的期望要求。</p><p>我们可能还希望将票价四舍五入到两位小数，因为它代表货币。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_df[&apos;Fare&apos;].fillna(test_df[&apos;Fare&apos;].dropna().median(), inplace=True)</span><br><span class="line">test_df.head()</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image29.png" alt="image29"><br>现在我们可以创建票价范围特征。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_df[&apos;FareBand&apos;] = pd.qcut(train_df[&apos;Fare&apos;], 4)</span><br><span class="line">train_df[[&apos;FareBand&apos;, &apos;Survived&apos;]].groupby([&apos;FareBand&apos;], as_index=False).mean().sort_values(by=&apos;FareBand&apos;, ascending=True)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image30.png" alt="image30"></p><p>根据FareBand将票价特征转换为序数值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for dataset in combine:</span><br><span class="line">    dataset.loc[ dataset[&apos;Fare&apos;] &lt;= 7.91, &apos;Fare&apos;] = 0</span><br><span class="line">    dataset.loc[(dataset[&apos;Fare&apos;] &gt; 7.91) &amp; (dataset[&apos;Fare&apos;] &lt;= 14.454), &apos;Fare&apos;] = 1</span><br><span class="line">    dataset.loc[(dataset[&apos;Fare&apos;] &gt; 14.454) &amp; (dataset[&apos;Fare&apos;] &lt;= 31), &apos;Fare&apos;]   = 2</span><br><span class="line">    dataset.loc[ dataset[&apos;Fare&apos;] &gt; 31, &apos;Fare&apos;] = 3</span><br><span class="line">    dataset[&apos;Fare&apos;] = dataset[&apos;Fare&apos;].astype(int)</span><br><span class="line"></span><br><span class="line">train_df = train_df.drop([&apos;FareBand&apos;], axis=1)</span><br><span class="line">combine = [train_df, test_df]</span><br><span class="line"></span><br><span class="line">train_df.head(10)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image31.png" alt="image31"></p><p>对测试数据集进行同样的操作。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_df.head(10)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image32.png" alt="image32"></p><h2 id="建模，预测和解决-问题"><a href="#建模，预测和解决-问题" class="headerlink" title="建模，预测和解决(问题)"></a>建模，预测和解决(问题)</h2><p>现在我们准备训练模型并预测所需的解决方案。 有60多种预测建模算法可供选择。 我们必须了解问题的类型和解决方案要求，以缩小到我们可以评估的少数几个模型。 我们的问题是分类和回归问题。 我们想要确定输出（幸存与否）与其他变量或特征（性别，年龄，港口……）之间的关系。 我们还使用了一种机器学习方法，称为监督学习，因为我们正在使用给定的数据集训练我们的模型。 有了这两个标准 - 监督学习加分类和回归，我们可以将我们选择的模型缩小到几个。 这些包括：</p><ul><li>Logistic回归</li><li>KNN 或  K近邻</li><li>支持向量机</li><li>朴素贝叶斯分类器</li><li>决策树</li><li>随机森林</li><li>感知机</li><li>人工神经网络</li><li>RVM或相关向量机</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X_train = train_df.drop(&quot;Survived&quot;, axis=1)</span><br><span class="line">Y_train = train_df[&quot;Survived&quot;]</span><br><span class="line">X_test  = test_df.drop(&quot;PassengerId&quot;, axis=1).copy()</span><br><span class="line">X_train.shape, Y_train.shape, X_test.shape</span><br></pre></td></tr></table></figure><blockquote><p>((891, 8), (891,), (418, 8))</p></blockquote><h3 id="Logistic回归"><a href="#Logistic回归" class="headerlink" title="Logistic回归"></a>Logistic回归</h3><p>Logistic回归是在工作流程中尽早使用的有用模型。 Logistic回归通过使用逻辑函数（累积逻辑分布，cumulative logistic distribution）估计概率来测量分类因变量（特征）与一个或多个自变量（特征）之间的关系。<a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank" rel="noopener">Logistic regression wikipedia</a></p><p>请注意模型基于我们的训练数据集生成的置信度分数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Logistic Regression</span><br><span class="line"></span><br><span class="line">logreg = LogisticRegression()</span><br><span class="line">logreg.fit(X_train, Y_train)</span><br><span class="line">Y_pred = logreg.predict(X_test)</span><br><span class="line">acc_log = round(logreg.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_log</span><br></pre></td></tr></table></figure><blockquote><p>80.36</p></blockquote><p>我们可以使用Logistic回归来验证我们对特征创建和完成目标的假设和决策。 这可以通过计算决策函数中特征间的系数来完成。</p><p>正系数增加了响应的对数几率(log-odds)（从而增加了概率），负系数降低了响应的对数几率（从而降低了概率）。</p><ul><li>性别是最高的正系数，暗示随着性别值的增加（male：0到female：1），Survived= 1的概率增加最多。</li><li>相反，随着Pclass的增加，Survived=1的概率降低最多。</li><li>由此可以看出，Age * Class 是一个很好的人工模型，因为它与Survived具有第二高的负相关。</li><li>Title(头衔)是第二高正相关。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">coeff_df = pd.DataFrame(train_df.columns.delete(0))</span><br><span class="line">coeff_df.columns = [&apos;Feature&apos;]</span><br><span class="line">coeff_df[&quot;Correlation&quot;] = pd.Series(logreg.coef_[0])</span><br><span class="line"></span><br><span class="line">coeff_df.sort_values(by=&apos;Correlation&apos;, ascending=False)</span><br></pre></td></tr></table></figure><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image33.png" alt="image33"></p><h3 id="SVM支持向量机"><a href="#SVM支持向量机" class="headerlink" title="SVM支持向量机"></a>SVM支持向量机</h3><p>接下来，我们使用支持向量机进行建模，支持向量机是监督学习模型，具有相关的学习算法，用于分析分类和回归分析。给定一组训练样本，每个训练样本被标记为属于两个类别中的一个或另一个，SVM训练算法构建将新测试样本分配给一个类别或另一个类别的模型，使其成为非概率二元线性分类器。 <a href="https://en.wikipedia.org/wiki/Support_vector_machine" target="_blank" rel="noopener">SVM_wikipedia</a></p><p>请注意，该模型生成的置信度得分高于Logistic回归模型。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Support Vector Machines</span><br><span class="line"></span><br><span class="line">svc = SVC()</span><br><span class="line">svc.fit(X_train, Y_train)</span><br><span class="line">Y_pred = svc.predict(X_test)</span><br><span class="line">acc_svc = round(svc.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_svc</span><br></pre></td></tr></table></figure></p><blockquote><p>83.84</p></blockquote><h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><p>在模式识别中，k-Nearest Neighbors算法（或简称k-NN）是用于分类和回归的非参数方法。 样本按其邻居的多数票进行分类，样本被分配给其k个最近邻居中最常见的类（k是正整数，通常很小）。 如果k = 1，则简单地将对象分配给该单个最近邻居的类。 <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank" rel="noopener">K-nearest_neighbors_algorithm_wikipedia</a></p><p>KNN置信度得分优于Logistic回归，但比SVM差。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">knn = KNeighborsClassifier(n_neighbors = 3)</span><br><span class="line">knn.fit(X_train, Y_train)</span><br><span class="line">Y_pred = knn.predict(X_test)</span><br><span class="line">acc_knn = round(knn.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_knn</span><br></pre></td></tr></table></figure></p><blockquote><p>84.74</p></blockquote><h3 id="朴素贝叶斯分类"><a href="#朴素贝叶斯分类" class="headerlink" title="朴素贝叶斯分类"></a>朴素贝叶斯分类</h3><p>在机器学习中，朴素贝叶斯分类器是一系列简单的概率分类器，它基于贝叶斯定理应用特征之间的强（朴素）独立假设。 朴素贝叶斯分类器具有高度可扩展性，在学习问题中需要多个变量（特征）的线性参数。 <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" target="_blank" rel="noopener">Naive_Bayes_classifier_wikipedia</a></p><p>该模型生成的置信度得分是迄今为止评估的模型中最低的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Gaussian Naive Bayes</span><br><span class="line"></span><br><span class="line">gaussian = GaussianNB()</span><br><span class="line">gaussian.fit(X_train, Y_train)</span><br><span class="line">Y_pred = gaussian.predict(X_test)</span><br><span class="line">acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_gaussian</span><br></pre></td></tr></table></figure></p><blockquote><p>72.28</p></blockquote><h3 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h3><p>感知器是用于二元分类器的监督学习算法（其功能可以判断由数字向量表示的输入是否属于某个特定类）。 它是一种线性分类器，即一种分类算法，其基于将一组权重与特征向量组合的线性预测函数进行其预测。 该算法允许在线学习，因为它一次一个地处理训练集中的元素。<a href="https://en.wikipedia.org/wiki/Perceptron" target="_blank" rel="noopener">Perceptron_wikipedia</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Perceptron</span><br><span class="line"></span><br><span class="line">perceptron = Perceptron()</span><br><span class="line">perceptron.fit(X_train, Y_train)</span><br><span class="line">Y_pred = perceptron.predict(X_test)</span><br><span class="line">acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_perceptron</span><br></pre></td></tr></table></figure></p><blockquote><p>78.0</p></blockquote><h3 id="线性支持向量分类"><a href="#线性支持向量分类" class="headerlink" title="线性支持向量分类"></a>线性支持向量分类</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Linear SVC</span><br><span class="line"></span><br><span class="line">linear_svc = LinearSVC()</span><br><span class="line">linear_svc.fit(X_train, Y_train)</span><br><span class="line">Y_pred = linear_svc.predict(X_test)</span><br><span class="line">acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_linear_svc</span><br></pre></td></tr></table></figure><blockquote><p>79.12</p></blockquote><h3 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Stochastic Gradient Descent</span><br><span class="line"></span><br><span class="line">sgd = SGDClassifier()</span><br><span class="line">sgd.fit(X_train, Y_train)</span><br><span class="line">Y_pred = sgd.predict(X_test)</span><br><span class="line">acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_sgd</span><br></pre></td></tr></table></figure><blockquote><p>78.56</p></blockquote><h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>该模型使用决策树作为预测模型，将特征（树枝）映射到关于目标值（树叶）的结论。 目标变量可以采用有限值集的树模型称为分类树; 在这些树结构中，叶子表示类标签，分支表示导致这些类标签的特征的连接。 目标变量可以采用连续值（通常是实数）的决策树称为回归树。<a href="https://en.wikipedia.org/wiki/Decision_tree_learning" target="_blank" rel="noopener">Decision_tree_learning_wikipedia</a></p><p>到目前为止评估的模型中该模型置信度得分最高。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Decision Tree</span><br><span class="line"></span><br><span class="line">decision_tree = DecisionTreeClassifier()</span><br><span class="line">decision_tree.fit(X_train, Y_train)</span><br><span class="line">Y_pred = decision_tree.predict(X_test)</span><br><span class="line">acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_decision_tree</span><br></pre></td></tr></table></figure></p><blockquote><p>86.76</p></blockquote><h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>下一个模型随机森林是最受欢迎的模型之一。 随机森林或随机决策森林是用于分类，回归和其他任务的集成学习方法，其通过在训练时构建多个决策树（n_estimators = 100）并输出作为类的模式的类（分类）来操作。 或者各树的预测（回归）平均值。 <a href="https://en.wikipedia.org/wiki/Random_forest" target="_blank" rel="noopener">Random_forest_wikipedia</a></p><p>到目前为止评估的模型中模型置信度得分最高。 我们决定使用此模型的输出（Y_pred）来创建竞赛结果提交。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Random Forest</span><br><span class="line"></span><br><span class="line">random_forest = RandomForestClassifier(n_estimators=100)</span><br><span class="line">random_forest.fit(X_train, Y_train)</span><br><span class="line">Y_pred = random_forest.predict(X_test)</span><br><span class="line">random_forest.score(X_train, Y_train)</span><br><span class="line">acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)</span><br><span class="line">acc_random_forest</span><br></pre></td></tr></table></figure></p><blockquote><p>86.76</p></blockquote><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>我们现在可以对所有模型进行评估，以便为我们的问题选择最佳模型。 虽然决策树和随机森林得分相同，但我们选择使用随机森林来纠正决策树过拟合的缺陷。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">models = pd.DataFrame(&#123;</span><br><span class="line">    &apos;Model&apos;: [&apos;Support Vector Machines&apos;, &apos;KNN&apos;, &apos;Logistic Regression&apos;,</span><br><span class="line">              &apos;Random Forest&apos;, &apos;Naive Bayes&apos;, &apos;Perceptron&apos;,</span><br><span class="line">              &apos;Stochastic Gradient Decent&apos;, &apos;Linear SVC&apos;,</span><br><span class="line">              &apos;Decision Tree&apos;],</span><br><span class="line">    &apos;Score&apos;: [acc_svc, acc_knn, acc_log,</span><br><span class="line">              acc_random_forest, acc_gaussian, acc_perceptron,</span><br><span class="line">              acc_sgd, acc_linear_svc, acc_decision_tree]&#125;)</span><br><span class="line">models.sort_values(by=&apos;Score&apos;, ascending=False)</span><br></pre></td></tr></table></figure></p><p><img src="https://github.com/hunterhawk/Kaggle-From-Scratch/blob/master/Titanic/res/image34.png" alt="image34"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">submission = pd.DataFrame(&#123;</span><br><span class="line">        &quot;PassengerId&quot;: test_df[&quot;PassengerId&quot;],</span><br><span class="line">        &quot;Survived&quot;: Y_pred</span><br><span class="line">    &#125;)</span><br><span class="line"># submission.to_csv(&apos;../output/submission.csv&apos;, index=False)</span><br></pre></td></tr></table></figure></p><p>我们向竞赛网站Kaggle提交的结果为6,082个参赛作品中的3,883个得分。 在比赛开始时，这个结果是指示性的。 此结果仅占提交数据集的一部分。 对我们的第一次尝试来说不错。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>该笔记是基于解决Titanic Competition的工作以及其他资源而创建的。</p><ul><li><a href="https://www.kaggle.com/omarelgabry/a-journey-through-titanic" target="_blank" rel="noopener">A journey through Titanic</a></li><li><a href="https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests" target="_blank" rel="noopener">Getting Started with Pandas: Kaggle’s Titanic Competition</a></li><li><a href="https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier" target="_blank" rel="noopener">Titanic Best Working Classifier</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;泰坦尼克号数据科学解决方案&quot;&gt;&lt;a href=&quot;#泰坦尼克号数据科学解决方案&quot; class=&quot;headerlink&quot; title=&quot;泰坦尼克号数据科学解决方案&quot;&gt;&lt;/a&gt;泰坦尼克号数据科学解决方案&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http
      
    
    </summary>
    
    
      <category term="Kaggle" scheme="http://hunterhawk.github.io/tags/Kaggle/"/>
    
      <category term="Data Science" scheme="http://hunterhawk.github.io/tags/Data-Science/"/>
    
      <category term="Python" scheme="http://hunterhawk.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://hunterhawk.github.io/2019/04/21/hello-world/"/>
    <id>http://hunterhawk.github.io/2019/04/21/hello-world/</id>
    <published>2019-04-21T14:16:59.240Z</published>
    <updated>2018-01-09T00:24:35.404Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="Test1" scheme="http://hunterhawk.github.io/categories/Test1/"/>
    
    
      <category term="Testing" scheme="http://hunterhawk.github.io/tags/Testing/"/>
    
      <category term="Technology" scheme="http://hunterhawk.github.io/tags/Technology/"/>
    
  </entry>
  
  <entry>
    <title>Blog部署流程</title>
    <link href="http://hunterhawk.github.io/2019/01/10/Blog%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B/"/>
    <id>http://hunterhawk.github.io/2019/01/10/Blog部署流程/</id>
    <published>2019-01-10T03:13:20.000Z</published>
    <updated>2019-01-10T04:58:00.363Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Install-Node"><a href="#Install-Node" class="headerlink" title="Install Node"></a>Install Node</h2><h2 id="Install-Git"><a href="#Install-Git" class="headerlink" title="Install Git"></a>Install Git</h2><h2 id="Install-Hexo"><a href="#Install-Hexo" class="headerlink" title="Install  Hexo"></a>Install  Hexo</h2><p>  use command : npm install -g hexo</p><h2 id="Create-the-project-folder-and-Init"><a href="#Create-the-project-folder-and-Init" class="headerlink" title="Create the project folder and Init"></a>Create the project folder and Init</h2><p>  use command : hexo init</p><h2 id="Generate-static-pages"><a href="#Generate-static-pages" class="headerlink" title="Generate static pages"></a>Generate static pages</h2><p>  use command : hexo generate (or hexo g)</p><h2 id="local-running"><a href="#local-running" class="headerlink" title="local running"></a>local running</h2><p>  use command : hexo server (default port:4000)<br>  if error: npm install hexo-server ; npm install hexo-server –save</p><h2 id="Access-with-Github"><a href="#Access-with-Github" class="headerlink" title="Access with Github"></a>Access with Github</h2><p>  open _config.yml,write in the deploy as following:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">type: git</span><br><span class="line">repository: git@github.com:[your name]/[your name].github.io.git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure><h2 id="deploy-steps"><a href="#deploy-steps" class="headerlink" title="deploy steps"></a>deploy steps</h2><ol><li>hexo clean</li><li>hexo generate</li><li>hexo deploy</li></ol><h2 id="useful-command"><a href="#useful-command" class="headerlink" title="useful command"></a>useful command</h2><table><thead><tr><th>命令</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td>hexo new “postName”</td><td style="text-align:center">新建文章</td></tr><tr><td>hexo new page “pageName”</td><td style="text-align:center">新建页面</td></tr><tr><td>hexo generate</td><td style="text-align:center">生成静态页面至public目录</td></tr><tr><td>hexo server</td><td style="text-align:center">开启预览访问端口（默认端口4000，’ctrl + c’关闭server）</td></tr><tr><td>hexo deploy</td><td style="text-align:center">将.deploy目录部署到GitHub</td></tr><tr><td>hexo help</td><td style="text-align:center">查看帮助</td></tr><tr><td>hexo version</td><td style="text-align:center">查看Hexo的版本</td></tr></tbody></table><h2 id="一些基本路径"><a href="#一些基本路径" class="headerlink" title="一些基本路径"></a>一些基本路径</h2><table><thead><tr><th style="text-align:center">操作</th><th style="text-align:center">路径</th></tr></thead><tbody><tr><td style="text-align:center">文章</td><td style="text-align:center">source/_posts</td></tr><tr><td style="text-align:center">修改头像、友情链接</td><td style="text-align:center">_config.yml</td></tr><tr><td style="text-align:center">修改名字</td><td style="text-align:center">public/index.html</td></tr></tbody></table><blockquote><p>参考<a href="http://leopardpan.github.io/" target="_blank" rel="noopener">http://leopardpan.github.io</a>整理</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Install-Node&quot;&gt;&lt;a href=&quot;#Install-Node&quot; class=&quot;headerlink&quot; title=&quot;Install Node&quot;&gt;&lt;/a&gt;Install Node&lt;/h2&gt;&lt;h2 id=&quot;Install-Git&quot;&gt;&lt;a href=&quot;#In
      
    
    </summary>
    
      <category term="Tutorial" scheme="http://hunterhawk.github.io/categories/Tutorial/"/>
    
    
      <category term="Hexo" scheme="http://hunterhawk.github.io/tags/Hexo/"/>
    
      <category term="Blog" scheme="http://hunterhawk.github.io/tags/Blog/"/>
    
  </entry>
  
  <entry>
    <title>2019 test</title>
    <link href="http://hunterhawk.github.io/2019/01/10/2019-test/"/>
    <id>http://hunterhawk.github.io/2019/01/10/2019-test/</id>
    <published>2019-01-10T02:52:12.000Z</published>
    <updated>2019-01-10T03:07:53.139Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2019-Blog-Test"><a href="#2019-Blog-Test" class="headerlink" title="2019 Blog Test"></a>2019 Blog Test</h1><h2 id="标题1"><a href="#标题1" class="headerlink" title="标题1"></a>标题1</h2><h3 id="标题2"><a href="#标题2" class="headerlink" title="标题2"></a>标题2</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2019-Blog-Test&quot;&gt;&lt;a href=&quot;#2019-Blog-Test&quot; class=&quot;headerlink&quot; title=&quot;2019 Blog Test&quot;&gt;&lt;/a&gt;2019 Blog Test&lt;/h1&gt;&lt;h2 id=&quot;标题1&quot;&gt;&lt;a href=&quot;#标题
      
    
    </summary>
    
    
      <category term="Security" scheme="http://hunterhawk.github.io/tags/Security/"/>
    
  </entry>
  
  <entry>
    <title>数据安全课程设计之恶意代码分析</title>
    <link href="http://hunterhawk.github.io/2018/01/08/%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%81%B6%E6%84%8F%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/"/>
    <id>http://hunterhawk.github.io/2018/01/08/数据安全课程设计之恶意代码分析/</id>
    <published>2018-01-08T02:23:56.000Z</published>
    <updated>2018-01-12T01:08:53.267Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目的和背景"><a href="#目的和背景" class="headerlink" title="目的和背景"></a>目的和背景</h1><h2 id="选题设计的背景"><a href="#选题设计的背景" class="headerlink" title="选题设计的背景"></a>选题设计的背景</h2><pre><code>随着网络技术的高速发展和信息时代的到来,通过互联网传播和共享信息资源已经成为人们的首选,然而,网络的开放性和灵活性在给人们带来便利的同时也引入了各式各样的安全问题。据国家互联网应急中心CNCERT 2008上半年的调查报告显示,各种网络安全事件数量与2007年上半年同期相比有较为显著的增加。在诸多的网络威胁中,恶意代码所占的比例和危害程度最大,国内外针对恶意代码的研究和防治工作也从各方面展开。而伴随着震网、火焰病毒等一系列震惊全球的重大网络安全事件的发生,信息安全已经上升到国家战略层面的高度。在此背景下,我国也面临着敌对势力恶意网络攻击的严重威胁。在信息网络安全的诸多威胁中,恶意代码的危害无疑最大,这也成为网络安全研究领域的焦点。目前,在恶意代码研究方面,国内反病毒厂商大多集中研发应用层面的产品,基础技术研究的精力相对较少；国外反病毒厂商在恶意代码检测方面的技术比较成熟,但涉及商业利益,很难从公开渠道获取相关信息。</code></pre><h2 id="选题设计的目的"><a href="#选题设计的目的" class="headerlink" title="选题设计的目的"></a>选题设计的目的</h2><pre><code>在该课程设计选题中，目的想要实现对于示例恶意代码的类型划分、静态分析、动态分析等分析研究，在通过前期对恶意代码分析技术的了解掌握后，最终结合Windows注册表、Windows API以及逆向反汇编技术，分析两个经典的恶意Windows程序，分别为“熊猫烧香（武汉男孩）”病毒和“永恒之蓝”比特勒索病毒，跟踪其恶意代码的运行过程，实现一定程度的对抗与逆向。最后，根据对于熊猫烧香病毒运行机制的分析，结合其特有的攻击方式以及造成的危害情况，使用Microsoft Visual Studio 2013 Ultimate编写具有简易图形化用户界面的专杀工具对其进行专门查杀以及系统清除。</code></pre><h2 id="全文章节概述"><a href="#全文章节概述" class="headerlink" title="全文章节概述"></a>全文章节概述</h2><pre><code>本文第一章节为前言部分，主要介绍恶意代码分析领域当前的研究现状以及面临的主要威胁，并介绍选题的目的及意义所在。本文第二章节为恶意代码分析的基础技术方法介绍，包括静态分析（调试）方法，动态分析（调试）方法，以及相应的恶意代码分析实战。该章节目的在于为接下来面对经典具体病毒的分析与防治奠定基础，并引入恶意代码分析领域。本文第三章节为对于经典病毒熊猫烧香（又名“武汉男孩”）的调试与分析，具体分为对于该病毒的概述介绍，静态调试过程，动态调试过程，以及防范措施的设想，为第五章节设计专杀工具做好准备工作。本文第四章节为对于近年席卷世界的“永恒之蓝”比特勒索病毒的调试与分析，具体分析过程同第四章节，在此不再赘述。本文第五章节为在第三章节的研究调试基础上进行的熊猫烧香病毒专杀工具的设计与实现，本文中采用C++结合MFC编写具有图形化用户界面的专杀工具，内容主要包括设计的详细思路，各模块的划分以及具体算法的实现，并最终通过测试验证该专杀工具的有效性。本文第六章节为结论与后记部分，主要包括对于本次数据安全课程设计的完成情况、有待改进之处、对于未来改进的展望以及心得体会等。</code></pre><h1 id="恶意代码分析基础"><a href="#恶意代码分析基础" class="headerlink" title="恶意代码分析基础"></a>恶意代码分析基础</h1><h2 id="恶意代码分析综述"><a href="#恶意代码分析综述" class="headerlink" title="恶意代码分析综述"></a>恶意代码分析综述</h2><h3 id="恶意代码分类简介"><a href="#恶意代码分类简介" class="headerlink" title="恶意代码分类简介"></a>恶意代码分类简介</h3><h3 id="文件加壳与恶意代码混淆"><a href="#文件加壳与恶意代码混淆" class="headerlink" title="文件加壳与恶意代码混淆"></a>文件加壳与恶意代码混淆</h3><h2 id="恶意代码调试方法及实战"><a href="#恶意代码调试方法及实战" class="headerlink" title="恶意代码调试方法及实战"></a>恶意代码调试方法及实战</h2><h3 id="Lab01-01-dll恶意文件分析"><a href="#Lab01-01-dll恶意文件分析" class="headerlink" title="Lab01-01.dll恶意文件分析"></a>Lab01-01.dll恶意文件分析</h3><h3 id="Lab01-01-exe恶意文件分析"><a href="#Lab01-01-exe恶意文件分析" class="headerlink" title="Lab01-01.exe恶意文件分析"></a>Lab01-01.exe恶意文件分析</h3><h2 id="分析结论与反病毒引擎测试"><a href="#分析结论与反病毒引擎测试" class="headerlink" title="分析结论与反病毒引擎测试"></a>分析结论与反病毒引擎测试</h2><h3 id="整体分析结论"><a href="#整体分析结论" class="headerlink" title="整体分析结论"></a>整体分析结论</h3><h3 id="反病毒引擎测试检验"><a href="#反病毒引擎测试检验" class="headerlink" title="反病毒引擎测试检验"></a>反病毒引擎测试检验</h3><h2 id="本章小结"><a href="#本章小结" class="headerlink" title="本章小结"></a>本章小结</h2><h1 id="熊猫烧香恶意代码分析"><a href="#熊猫烧香恶意代码分析" class="headerlink" title="熊猫烧香恶意代码分析"></a>熊猫烧香恶意代码分析</h1><h2 id="熊猫烧香病毒概述"><a href="#熊猫烧香病毒概述" class="headerlink" title="熊猫烧香病毒概述"></a>熊猫烧香病毒概述</h2><h3 id="测试环境及工具简介"><a href="#测试环境及工具简介" class="headerlink" title="测试环境及工具简介"></a>测试环境及工具简介</h3><h3 id="病毒行为流程"><a href="#病毒行为流程" class="headerlink" title="病毒行为流程"></a>病毒行为流程</h3><h2 id="病毒危害行为分析"><a href="#病毒危害行为分析" class="headerlink" title="病毒危害行为分析"></a>病毒危害行为分析</h2><h3 id="运行病毒"><a href="#运行病毒" class="headerlink" title="运行病毒"></a>运行病毒</h3><h3 id="系统目录创建病毒程序"><a href="#系统目录创建病毒程序" class="headerlink" title="系统目录创建病毒程序"></a>系统目录创建病毒程序</h3><h3 id="各目录生成Desktop-ini记录文件"><a href="#各目录生成Desktop-ini记录文件" class="headerlink" title="各目录生成Desktop_.ini记录文件"></a>各目录生成Desktop_.ini记录文件</h3><h3 id="感染全盘二进制文件与脚本文件"><a href="#感染全盘二进制文件与脚本文件" class="headerlink" title="感染全盘二进制文件与脚本文件"></a>感染全盘二进制文件与脚本文件</h3><h3 id="添加系统开机启动项"><a href="#添加系统开机启动项" class="headerlink" title="添加系统开机启动项"></a>添加系统开机启动项</h3><h3 id="盘符根目录生成setup-exe与autorun-inf文件"><a href="#盘符根目录生成setup-exe与autorun-inf文件" class="headerlink" title="盘符根目录生成setup.exe与autorun.inf文件"></a>盘符根目录生成setup.exe与autorun.inf文件</h3><h2 id="病毒恶意代码分析"><a href="#病毒恶意代码分析" class="headerlink" title="病毒恶意代码分析"></a>病毒恶意代码分析</h2><h3 id="病毒自我复制分析"><a href="#病毒自我复制分析" class="headerlink" title="病毒自我复制分析"></a>病毒自我复制分析</h3><h3 id="病毒感染全盘分析"><a href="#病毒感染全盘分析" class="headerlink" title="病毒感染全盘分析"></a>病毒感染全盘分析</h3><h3 id="病毒自我保护分析"><a href="#病毒自我保护分析" class="headerlink" title="病毒自我保护分析"></a>病毒自我保护分析</h3><h2 id="病毒代码整体分析总结"><a href="#病毒代码整体分析总结" class="headerlink" title="病毒代码整体分析总结"></a>病毒代码整体分析总结</h2><h3 id="病毒恶意行为总结"><a href="#病毒恶意行为总结" class="headerlink" title="病毒恶意行为总结"></a>病毒恶意行为总结</h3><h3 id="解决方案设计"><a href="#解决方案设计" class="headerlink" title="解决方案设计"></a>解决方案设计</h3><h2 id="反病毒引擎测试检验-1"><a href="#反病毒引擎测试检验-1" class="headerlink" title="反病毒引擎测试检验"></a>反病毒引擎测试检验</h2><h2 id="本章小结-1"><a href="#本章小结-1" class="headerlink" title="本章小结"></a>本章小结</h2><h1 id="熊猫烧香专杀工具的设计与实现"><a href="#熊猫烧香专杀工具的设计与实现" class="headerlink" title="熊猫烧香专杀工具的设计与实现"></a>熊猫烧香专杀工具的设计与实现</h1><h2 id="设计思想阐述"><a href="#设计思想阐述" class="headerlink" title="设计思想阐述"></a>设计思想阐述</h2><h2 id="界面设计实现"><a href="#界面设计实现" class="headerlink" title="界面设计实现"></a>界面设计实现</h2><h2 id="重点算法模块"><a href="#重点算法模块" class="headerlink" title="重点算法模块"></a>重点算法模块</h2><h3 id="CRC32算法计算散列值"><a href="#CRC32算法计算散列值" class="headerlink" title="CRC32算法计算散列值"></a>CRC32算法计算散列值</h3><h3 id="查找进程与提升权限"><a href="#查找进程与提升权限" class="headerlink" title="查找进程与提升权限"></a>查找进程与提升权限</h3><h3 id="查找并删除Desktop-ini文件"><a href="#查找并删除Desktop-ini文件" class="headerlink" title="查找并删除Desktop_.ini文件"></a>查找并删除Desktop_.ini文件</h3><h3 id="遍历并结束spoclsv-exe进程"><a href="#遍历并结束spoclsv-exe进程" class="headerlink" title="遍历并结束spoclsv.exe进程"></a>遍历并结束spoclsv.exe进程</h3><h3 id="删除每个盘符下的setup-exe与autorun-inf文件"><a href="#删除每个盘符下的setup-exe与autorun-inf文件" class="headerlink" title="删除每个盘符下的setup.exe与autorun.inf文件"></a>删除每个盘符下的setup.exe与autorun.inf文件</h3><h3 id="修复注册表内容"><a href="#修复注册表内容" class="headerlink" title="修复注册表内容"></a>修复注册表内容</h3><h2 id="工具测试与自评"><a href="#工具测试与自评" class="headerlink" title="工具测试与自评"></a>工具测试与自评</h2><h2 id="本章小结-2"><a href="#本章小结-2" class="headerlink" title="本章小结"></a>本章小结</h2><h1 id="“永恒之蓝”比特勒索病毒"><a href="#“永恒之蓝”比特勒索病毒" class="headerlink" title="“永恒之蓝”比特勒索病毒"></a>“永恒之蓝”比特勒索病毒</h1><h2 id="“永恒之蓝”比特勒索病毒概述"><a href="#“永恒之蓝”比特勒索病毒概述" class="headerlink" title="“永恒之蓝”比特勒索病毒概述"></a>“永恒之蓝”比特勒索病毒概述</h2><h2 id="病毒行为分析"><a href="#病毒行为分析" class="headerlink" title="病毒行为分析"></a>病毒行为分析</h2><h2 id="解决方案与防范措施"><a href="#解决方案与防范措施" class="headerlink" title="解决方案与防范措施"></a>解决方案与防范措施</h2><h2 id="本章小结-3"><a href="#本章小结-3" class="headerlink" title="本章小结"></a>本章小结</h2><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目的和背景&quot;&gt;&lt;a href=&quot;#目的和背景&quot; class=&quot;headerlink&quot; title=&quot;目的和背景&quot;&gt;&lt;/a&gt;目的和背景&lt;/h1&gt;&lt;h2 id=&quot;选题设计的背景&quot;&gt;&lt;a href=&quot;#选题设计的背景&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
    
      <category term="Security" scheme="http://hunterhawk.github.io/tags/Security/"/>
    
  </entry>
  
  <entry>
    <title>test1</title>
    <link href="http://hunterhawk.github.io/2018/01/08/test1/"/>
    <id>http://hunterhawk.github.io/2018/01/08/test1/</id>
    <published>2018-01-08T01:18:13.000Z</published>
    <updated>2018-01-08T02:18:36.630Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一级标题1"><a href="#一级标题1" class="headerlink" title="一级标题1"></a>一级标题1</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">"hello word"</span>)</span><br></pre></td></tr></table></figure><h2 id="二级标题1"><a href="#二级标题1" class="headerlink" title="二级标题1"></a>二级标题1</h2><h3 id="三级标题1"><a href="#三级标题1" class="headerlink" title="三级标题1"></a>三级标题1</h3><h3 id="三级标题2"><a href="#三级标题2" class="headerlink" title="三级标题2"></a>三级标题2</h3><h2 id="二级标题2"><a href="#二级标题2" class="headerlink" title="二级标题2"></a>二级标题2</h2><h3 id="三级标题3"><a href="#三级标题3" class="headerlink" title="三级标题3"></a>三级标题3</h3><h1 id="一级标题2"><a href="#一级标题2" class="headerlink" title="一级标题2"></a>一级标题2</h1><h2 id="二级标题3"><a href="#二级标题3" class="headerlink" title="二级标题3"></a>二级标题3</h2><h3 id="三级标题4"><a href="#三级标题4" class="headerlink" title="三级标题4"></a>三级标题4</h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一级标题1&quot;&gt;&lt;a href=&quot;#一级标题1&quot; class=&quot;headerlink&quot; title=&quot;一级标题1&quot;&gt;&lt;/a&gt;一级标题1&lt;/h1&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;
      
    
    </summary>
    
    
  </entry>
  
</feed>
